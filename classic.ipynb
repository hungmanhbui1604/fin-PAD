{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import get_dataloader\n",
    "from models.dual_model import DualModel\n",
    "from metrics import find_optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRA = True\n",
    "YEAR = 'foreground_2015'\n",
    "SENSOR = 'CrossMatch'\n",
    "DATASET_PATH = '/home/hmb1604/datasets/LivDet'\n",
    "BINARY_CLASS = True\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "MODEL_SAVED_PATH = './ckpts/model.pth'\n",
    "os.makedirs('./ckpts', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd246cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = {\n",
    "    'Train': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomAffine(\n",
    "            degrees=(-20, 20),          # Rotation\n",
    "            translate=(0.2, 0.2),       # Horizontal/vertical shift\n",
    "            shear=(-20, 20),            # Shear\n",
    "            scale=(0.8, 1.2),           # Zoom\n",
    "            interpolation=T.InterpolationMode.NEAREST,\n",
    "            fill=0\n",
    "        ),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "\n",
    "    'Test': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, train_label_map = get_dataloader(intra=INTRA, year=YEAR, sensor=SENSOR, dataset_path=DATASET_PATH, train=True, binary_class=BINARY_CLASS, transform=transform, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_loader, test_label_map = get_dataloader(intra=INTRA, year=YEAR, sensor=SENSOR, dataset_path=DATASET_PATH, train=False, binary_class=BINARY_CLASS, transform=transform, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DualModel(num_classes=1).to(device=device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_losses': [],\n",
    "    'val_losses': [],\n",
    "    'best_val_loss': 1e3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dfec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Begin training...')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_train_loss = 0.0\n",
    "    \n",
    "    for idx, (imgs, labels) in enumerate(tqdm(train_loader, desc=f\"train epoch [{epoch+1}/{NUM_EPOCHS}]\")):\n",
    "        imgs, labels = imgs.to(device), labels.to(device, dtype=torch.float)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs.squeeze(1), labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    history['train_losses'].append(avg_train_loss)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_loader, desc=f\"val epoch [{epoch+1}/{NUM_EPOCHS}]\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device, dtype=torch.float)\n",
    "            \n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs.squeeze(1), labels)\n",
    "            total_val_loss += loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    history['val_losses'].append(avg_val_loss)\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{NUM_EPOCHS}] Train Loss [{avg_train_loss:.4f}] Val Loss: [{avg_val_loss:.4f}]')\n",
    "\n",
    "    if avg_val_loss < history['best_val_loss']:\n",
    "        history['best_val_loss'] = avg_val_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVED_PATH)\n",
    "        print(f'Model saved!')\n",
    "\n",
    "    print('=' * 63)\n",
    "\n",
    "print('Finish training...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f27a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "plt.plot(history['train_losses'], label='Train Loss')\n",
    "plt.plot(history['val_losses'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b222b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_SAVED_PATH))\n",
    "\n",
    "# Testing phase\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device, dtype=torch.float)\n",
    "        \n",
    "        outputs = model(imgs)\n",
    "        probabilities = torch.sigmoid(outputs.squeeze(1))\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "labels = np.array(all_labels).astype(int)\n",
    "probabilities = np.array(all_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9824743",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, apcer, bpcer, accuracy, ace, accuracy = find_optimal_threshold(labels, probabilities, based_on=\"ace\")\n",
    "print(f\"APCER:      {apcer*100:.2f}%\")\n",
    "print(f\"BPCER:      {bpcer*100:.2f}%\")\n",
    "print(f\"ACE:        {ace*100:.2f}%\")\n",
    "print(f\"Accuracy:   {accuracy*100:.2f}%\")\n",
    "print(f\"Accuracy*:  {(1-ace)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22464323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
