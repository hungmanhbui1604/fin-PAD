{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847ba16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import get_dataloader\n",
    "from models.multitask_models import MultitaskModel, MobileNetV2Backbone\n",
    "from metrics import compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INTRA = True\n",
    "YEAR = 'foreground_2015'\n",
    "SENSOR = 'CrossMatch'\n",
    "DATASET_PATH = '/home/hmb1604/datasets/LivDet'\n",
    "BINARY_CLASS = False\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_EPOCHS = 1\n",
    "\n",
    "SPOOF_WEIGHT = 3.6\n",
    "MATERIAL_WEIGHT = 1.0\n",
    "THRESHOLD = 0.5\n",
    "\n",
    "MODEL_SAVE_PATH = './ckpts/model.pth'\n",
    "os.makedirs('./ckpts', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd246cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = {\n",
    "    'Train': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.RandomHorizontalFlip(p=0.5),\n",
    "        T.RandomVerticalFlip(p=0.5),\n",
    "        T.RandomAffine(\n",
    "            degrees=(-20, 20),          # Rotation\n",
    "            translate=(0.2, 0.2),       # Horizontal/vertical shift\n",
    "            shear=(-20, 20),            # Shear\n",
    "            scale=(0.8, 1.2),           # Zoom\n",
    "            interpolation=T.InterpolationMode.NEAREST,\n",
    "            fill=0\n",
    "        ),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "\n",
    "    'Test': T.Compose([\n",
    "        T.Resize((224, 224)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7b4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, train_label_map = get_dataloader(intra=INTRA, year=YEAR, sensor=SENSOR, dataset_path=DATASET_PATH, train=True, binary_class=BINARY_CLASS, transform=transform, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "test_loader, test_label_map = get_dataloader(intra=INTRA, year=YEAR, sensor=SENSOR, dataset_path=DATASET_PATH, train=False, binary_class=BINARY_CLASS, transform=transform, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f82be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = MobileNetV2Backbone()\n",
    "model = MultitaskModel(feature_extractor=backbone, num_material_classes=len(train_label_map)-1).to(device)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d478b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "spoof_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "material_criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168fc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'train_total_loss': [],\n",
    "    'train_spoof_loss': [],\n",
    "    'train_material_loss': [],\n",
    "    'train_spoof_acc': [],\n",
    "    'train_material_acc': [],\n",
    "    'val_total_loss': [],\n",
    "    'val_spoof_loss': [],\n",
    "    'val_material_loss': [],\n",
    "    'val_spoof_acc': [],\n",
    "    'val_material_acc': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
    "    print('-' * 36)\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_spoof_loss = 0.0\n",
    "    running_material_loss = 0.0\n",
    "    running_total_loss = 0.0\n",
    "    running_correct_spoof = 0\n",
    "    running_correct_material = 0\n",
    "    total_samples = 0\n",
    "    total_spoof_samples = 0\n",
    "    \n",
    "    for imgs, labels in tqdm(train_loader, desc=\"train\"):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device, dtype=torch.float)\n",
    "        \n",
    "        spoof_labels = (labels > 0).float().unsqueeze(1)\n",
    "        \n",
    "        material_labels = (labels - 1).long()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        spoof_outputs, material_outputs = model(imgs)\n",
    "        \n",
    "        spoof_loss = spoof_criterion(spoof_outputs, spoof_labels)\n",
    "        \n",
    "        spoof_indices = (spoof_labels.squeeze() == 1).nonzero(as_tuple=True)[0]\n",
    "        if len(spoof_indices) > 0:\n",
    "            spoof_material_outputs = material_outputs[spoof_indices]\n",
    "            spoof_material_labels = material_labels[spoof_indices]\n",
    "            material_loss = material_criterion(spoof_material_outputs, spoof_material_labels)\n",
    "        else:\n",
    "            material_loss = torch.tensor(0.0, device=device, requires_grad=True)\n",
    "        \n",
    "        total_loss = SPOOF_WEIGHT * spoof_loss + MATERIAL_WEIGHT * material_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_spoof_loss += spoof_loss.item()\n",
    "        running_material_loss += material_loss.item()\n",
    "        running_total_loss += total_loss.item()\n",
    "        \n",
    "        spoof_preds = (spoof_outputs > THRESHOLD).float()\n",
    "        running_correct_spoof += (spoof_preds == spoof_labels).sum().item()\n",
    "        \n",
    "        if len(spoof_indices) > 0:\n",
    "            spoof_material_preds = torch.argmax(spoof_material_outputs, dim=1)\n",
    "            running_correct_material += (spoof_material_preds == spoof_material_labels).sum().item()\n",
    "            total_spoof_samples += len(spoof_indices)\n",
    "        \n",
    "        total_samples += imgs.size(0)\n",
    "    \n",
    "    epoch_spoof_loss = running_spoof_loss / len(train_loader)\n",
    "    epoch_material_loss = running_material_loss / len(train_loader)\n",
    "    epoch_total_loss = running_total_loss / len(train_loader)\n",
    "    epoch_spoof_acc = (running_correct_spoof / total_samples) * 100.0\n",
    "    epoch_material_acc = (running_correct_material / total_spoof_samples) * 100.0 if total_spoof_samples > 0 else 0.0\n",
    "    \n",
    "    print(f'Train Loss: Total=[{epoch_total_loss:.4f}] Spoof=[{epoch_spoof_loss:.4f}] Material=[{epoch_material_loss:.4f}]')\n",
    "    print(f'Train Acc: Spoof=[{epoch_spoof_acc:.2f}] Material=[{epoch_material_acc:.2f}]')\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_spoof_loss = 0.0\n",
    "    val_material_loss = 0.0\n",
    "    val_total_loss = 0.0\n",
    "    val_correct_spoof = 0\n",
    "    val_correct_material = 0\n",
    "    val_total_samples = 0\n",
    "    val_spoof_samples_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(val_loader, desc=\"val\"):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device, dtype=torch.float)\n",
    "            \n",
    "            spoof_labels = (labels > 0).float().unsqueeze(1)\n",
    "            material_labels = (labels - 1).long()\n",
    "            \n",
    "            spoof_outputs, material_outputs = model(imgs)\n",
    "            \n",
    "            spoof_loss = spoof_criterion(spoof_outputs, spoof_labels)\n",
    "            \n",
    "            spoof_indices = (spoof_labels.squeeze() == 1).nonzero(as_tuple=True)[0]\n",
    "            if len(spoof_indices) > 0:\n",
    "                spoof_material_outputs = material_outputs[spoof_indices]\n",
    "                spoof_material_labels = material_labels[spoof_indices]\n",
    "                material_loss = material_criterion(spoof_material_outputs, spoof_material_labels)\n",
    "            else:\n",
    "                material_loss = torch.tensor(0.0, device=device)\n",
    "            \n",
    "            total_loss = SPOOF_WEIGHT * spoof_loss + MATERIAL_WEIGHT * material_loss\n",
    "            \n",
    "            val_spoof_loss += spoof_loss.item()\n",
    "            val_material_loss += material_loss.item()\n",
    "            val_total_loss += total_loss.item()\n",
    "            \n",
    "            spoof_preds = (spoof_outputs > THRESHOLD).float()\n",
    "            val_correct_spoof += (spoof_preds == spoof_labels).sum().item()\n",
    "            \n",
    "            if len(spoof_indices) > 0:\n",
    "                spoof_material_preds = torch.argmax(spoof_material_outputs, dim=1)\n",
    "                val_correct_material += (spoof_material_preds == spoof_material_labels).sum().item()\n",
    "            \n",
    "            val_total_samples += imgs.size(0)\n",
    "            val_spoof_samples_total += spoof_labels.sum().item()\n",
    "    \n",
    "    val_epoch_spoof_loss = val_spoof_loss / len(val_loader)\n",
    "    val_epoch_material_loss = val_material_loss / len(val_loader)\n",
    "    val_epoch_total_loss = val_total_loss / len(val_loader)\n",
    "    val_epoch_spoof_acc = (val_correct_spoof / val_total_samples) * 100.0\n",
    "    val_epoch_material_acc = (val_correct_material / val_spoof_samples_total) * 100.0 if val_spoof_samples_total > 0 else 0.0\n",
    "    \n",
    "    print(f'Val Loss: Total=[{val_epoch_total_loss:.4f}] Spoof=[{val_epoch_spoof_loss:.4f}] Material=[{val_epoch_material_loss:.4f}]')\n",
    "    print(f'Val Acc: Spoof=[{val_epoch_spoof_acc:.2f}] Material=[{val_epoch_material_acc:.2f}]')\n",
    "    print()\n",
    "    \n",
    "    history['train_total_loss'].append(epoch_total_loss)\n",
    "    history['train_spoof_loss'].append(epoch_spoof_loss)\n",
    "    history['train_material_loss'].append(epoch_material_loss)\n",
    "    history['train_spoof_acc'].append(epoch_spoof_acc)\n",
    "    history['train_material_acc'].append(epoch_material_acc)\n",
    "    \n",
    "    history['val_total_loss'].append(val_epoch_total_loss)\n",
    "    history['val_spoof_loss'].append(val_epoch_spoof_loss)\n",
    "    history['val_material_loss'].append(val_epoch_material_loss)\n",
    "    history['val_spoof_acc'].append(val_epoch_spoof_acc)\n",
    "    history['val_material_acc'].append(val_epoch_material_acc)\n",
    "    \n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    if val_epoch_total_loss < best_val_loss:\n",
    "        best_val_loss = val_epoch_total_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\"New best model found! Saving to {MODEL_SAVE_PATH}\")\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': best_model_state,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'best_val_loss': best_val_loss,\n",
    "            'history': history\n",
    "        }, MODEL_SAVE_PATH)\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "if best_model_state is not None:\n",
    "    model.load_state_dict(best_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f27a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15))\n",
    "\n",
    "ax1.plot(history['train_total_loss'], label='Train Total Loss')\n",
    "ax1.plot(history['train_spoof_loss'], label='Train Spoof Loss')\n",
    "ax1.plot(history['train_material_loss'], label='Train Material Loss')\n",
    "ax1.plot(history['val_total_loss'], label='Val Total Loss')\n",
    "ax1.plot(history['val_spoof_loss'], label='Val Spoof Loss')\n",
    "ax1.plot(history['val_material_loss'], label='Val Material Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "ax1.set_title('Training and Validation Losses')\n",
    "\n",
    "ax2.plot(history['train_spoof_acc'], label='Train Spoof Acc')\n",
    "ax2.plot(history['train_material_acc'], label='Train Material Acc')\n",
    "ax2.plot(history['val_spoof_acc'], label='Val Spoof Acc')\n",
    "ax2.plot(history['val_material_acc'], label='Val Material Acc')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "ax2.set_title('Training and Validation Accuracies')\n",
    "\n",
    "ax3.plot(history['lr'], label='Learning Rate')\n",
    "ax3.set_xlabel('Epoch')\n",
    "ax3.set_ylabel('Learning Rate')\n",
    "ax3.legend()\n",
    "ax3.grid(True)\n",
    "ax3.set_title('Learning Rate Schedule')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b222b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing phase\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device, dtype=torch.float)\n",
    "\n",
    "        spoof_labels = (labels > 0).float()\n",
    "        \n",
    "        spoof_outputs, material_outputs = model(imgs)\n",
    "\n",
    "        probabilities = torch.sigmoid(spoof_outputs.squeeze(1))\n",
    "        \n",
    "        all_labels.extend(spoof_labels.cpu().numpy())\n",
    "        all_probabilities.extend(probabilities.cpu().numpy())\n",
    "\n",
    "labels = np.array(all_labels).astype(int)\n",
    "probabilities = np.array(all_probabilities)\n",
    "predictions = (probabilities >= THRESHOLD).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9824743",
   "metadata": {},
   "outputs": [],
   "source": [
    "apcer, bpcer, ace, accuracy = compute_metrics(labels, predictions)\n",
    "print(f\"APCER:      {apcer*100:.2f}%\")\n",
    "print(f\"BPCER:      {bpcer*100:.2f}%\")\n",
    "print(f\"ACE:        {ace*100:.2f}%\")\n",
    "print(f\"Accuracy:   {accuracy*100:.2f}%\")\n",
    "print(f\"Accuracy*:  {(1-ace)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22464323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
